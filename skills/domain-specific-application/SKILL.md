---
name: Domain-Specific Application
description: Apply the right cognitive biases to the right situations based on domain context
when_to_use: before entering high-stakes domain decisions, onboarding to new role/responsibility, or reviewing recurring decision patterns
version: 1.0.0
---

# Domain-Specific Application

## Overview: Why Domain Specificity Matters

Different domains activate different cognitive biases with varying intensity and consequences. A bias that merely creates minor inefficiency in one context can lead to catastrophic failure in another. For example, the Halo Effect in hiring can result in years of poor performance and cultural damage, while the same bias in choosing a restaurant might just mean a mediocre meal. Understanding which biases are "hot" in your specific domain enables targeted vigilance where it matters most.

Generic bias awareness—knowing that confirmation bias exists—provides limited protection. What transforms knowledge into power is understanding *when* and *where* specific biases strike hardest in your daily work. A surgeon needs to guard against premature closure in diagnosis; an executive against groupthink in strategy sessions; a product designer against dark pattern temptations. Each domain has its own "bias profile"—patterns that emerge repeatedly from the structural features of that decision environment.

The curated lists in your Cognitive Biases vault provide battle-tested, domain-specific guidance. Each list represents distilled wisdom: the biases that practitioners in that field have found most dangerous, along with proven mitigation strategies tailored to that context. This skill teaches you how to leverage these domain guides for maximum impact—turning bias awareness from abstract knowledge into concrete decision improvements in your specific area of work.

## The 8 Domain Guides

### Domain 1: Hiring & Recruitment

**Location:** `[[Hiring Recruitment 10 - Curated Biases]]`
**Vault Path:** `/Users/tijlkoenderink/Library/Mobile Documents/iCloud~md~obsidian/Documents/Obsidian-Private/01-Private/03-RESOURCES/Cognitive Biases/Curated-Lists/Hiring Recruitment 10 - Curated Biases.md`

**High-Risk Biases:**
- **[[Halo Effect]]** - First impression (appearance, charisma, alma mater) dominates entire evaluation, overriding actual skills assessment
- **[[Affinity Bias]]** - "Like me" candidates seem inherently better qualified; shared background confused with competence
- **[[Confirmation Bias]]** - Early positive or negative opinion drives subsequent question selection to confirm initial judgment
- **[[Anchoring Bias]]** - First candidate sets implicit standard; subsequent candidates judged relative to anchor, not role requirements
- **[[Contrast Effect]]** - Comparing candidates to each other rather than to objective role criteria; mediocre candidate after weak ones seems excellent

**Domain Red Flags:**
- "I decided in the first 5 minutes of the interview"
- "Great culture fit" without defining what that means behaviorally
- "Gut feeling says this is the one"
- Unstructured interviews where questions vary by candidate
- No scoring system or defined evaluation criteria
- Post-interview rationalization: "I just knew"

**Mitigation Specific to Domain:**
- **Structured interviews:** Same questions, same order, for every candidate; eliminates variance that triggers biases
- **Scorecards defined pre-interview:** Decide evaluation criteria before seeing candidates; prevents moving goalposts
- **Blind resume review:** Remove names, photos, university names initially; evaluate skills first
- **Multiple independent interviewers:** Each scores separately before discussion; prevents groupthink
- **Compare to role, not candidates:** Judge each against job requirements, not against other applicants
- **Define "culture fit":** Translate vague feeling into specific observable behaviors required for team success

**Success/Failure Stories:**
- **Success:** Google's structured hiring process reduced bias and improved quality-of-hire metrics by implementing scorecards, structured interviews, and committee-based decisions. Result: more diverse teams with higher performance ratings.
- **Failure:** Traditional "culture fit" interviews at many tech companies led to homogeneous teams that missed market opportunities. Unstructured "beer test" interviews systematically excluded qualified candidates who didn't match interviewer's background.

**Checklist:** [From Pre-Decision Checklist - Hiring Section]
- [ ] Defined role requirements before seeing candidates?
- [ ] Using structured interview with standardized questions?
- [ ] Scorecard completed independently before team discussion?
- [ ] Explicitly checked for affinity bias (do I like them because they're like me)?
- [ ] Compared to role requirements, not to other candidates?
- [ ] Can I name specific examples supporting my evaluation, not just general impressions?

---

### Domain 2: Executive/Strategic Decisions

**Location:** `[[Executive Top 10 - Curated Biases]]`
**Vault Path:** `/Users/tijlkoenderink/Library/Mobile Documents/iCloud~md~obsidian/Documents/Obsidian-Private/01-Private/03-RESOURCES/Cognitive Biases/Curated-Lists/Executive Top 10 - Curated Biases.md`

**High-Risk Biases:**
- **[[Confirmation Bias]]** - Seeking evidence that supports preferred strategic direction while dismissing contradictory data
- **[[Overconfidence Bias]]** - Underestimating risks, overestimating organizational capabilities, believing "we're different"
- **[[Groupthink]]** - Unanimous agreement without genuine dissent; premature consensus driven by social cohesion
- **[[Anchoring Bias]]** - First proposal presented dominates discussion; alternatives judged relative to initial suggestion
- **[[Sunk Cost Fallacy]]** - Continuing failed strategy due to past investment ("we've already spent $10M"); throwing good money after bad

**Domain Red Flags:**
- No dissenting voices in strategic discussions
- Unanimous enthusiasm without critical examination
- "We've never failed before" or "This is our core competency"
- Aggressive timelines with no buffer for unknowns
- Dismissing competitor threats as "they don't understand the market"
- Leaders speaking first and dominating discussion
- No consideration of "what could go wrong"

**Mitigation Specific to Domain:**
- **Kahneman's 12-point executive checklist:** Systematic bias check before major decisions (from [[Pre-Decision Checklist]])
- **Mandatory devil's advocate:** Assign someone to argue against proposal; rotate role to prevent stigmatization
- **Pre-mortem before approval:** "It's 2 years from now and this strategy failed spectacularly. Why?" Surface hidden concerns
- **Outside view:** What happened to other companies that tried this? Base rate analysis
- **Independent estimates:** Each executive writes down projections before group discussion; prevents anchoring

**Success/Failure Stories:**
- **Success:** Intel's strategic shift from memory to processors. Andy Grove's paranoia culture encouraged dissent; survival required abandoning past success despite sunk costs. Result: market dominance for decades.
- **Failure:** Kodak's digital camera denial. Groupthink around film profitability, sunk cost in manufacturing, overconfidence in brand. Invented digital camera but failed to pursue. Result: bankruptcy.

**Checklist:** [From Pre-Decision Checklist - Executive Section]
- [ ] Have we sought disconfirming evidence for this strategy?
- [ ] What's the outside view? (What happened to others who tried this?)
- [ ] Have we explicitly discussed what could go wrong?
- [ ] Are there dissenting voices, or just unanimous agreement?
- [ ] Have we separated past investment from future potential?
- [ ] Are our timelines based on realistic assessment or optimism?

---

### Domain 3: Product Design & UX

**Location:** `[[UX Product Design 15 - Curated Biases]]`
**Vault Path:** `/Users/tijlkoenderink/Library/Mobile Documents/iCloud~md~obsidian/Documents/Obsidian-Private/01-Private/03-RESOURCES/Cognitive Biases/Curated-Lists/UX Product Design 15 - Curated Biases.md`

**High-Risk Biases:**
- **[[Anchoring Bias]]** - First price shown affects perceived value; initial number dominates subsequent judgment
- **[[Decoy Effect]]** - Adding strategically inferior option makes target option more attractive
- **[[Loss Aversion]]** - Fear of losing outweighs potential gain; "Don't lose your progress!" drives behavior
- **[[Social Proof]]** - "1 million users downloaded this" or "Your friends are using this" drives adoption
- **[[Peak-End Rule]]** - Experience judged by peak moment and ending, not overall quality; can hide problems

**Domain Red Flags:**
- Dark patterns: intentional design to manipulate users against their interest
- Short-term metrics (clicks, conversions) prioritized over long-term user value
- "Everyone does this" as justification for questionable practice
- Exploiting biases without providing genuine user benefit
- A/B testing without considering ethical implications
- Hiding true costs or making unsubscribe difficult

**Mitigation Specific to Domain:**
- **Ethical design checklist:** Would I want this used on my family? Does this genuinely help users?
- **User research beyond metrics:** Talk to users; understand needs, not just behaviors
- **A/B testing with long-term metrics:** Track satisfaction, retention, trust—not just immediate conversion
- **Transparency over manipulation:** Make costs, commitments, and options clear
- **Bias use for user benefit:** Guide toward better choices, don't exploit for profit
- **Regular ethics review:** Team discussion of whether design serves users or exploits them

**Success/Failure Stories:**
- **Success:** Duolingo's positive reinforcement design uses streak tracking (loss aversion) and social proof ethically—keeping users engaged in language learning that benefits them. Users report genuine progress and satisfaction.
- **Failure:** Dark patterns in e-commerce (hidden costs until checkout, difficult unsubscribe, fake scarcity) generate short-term revenue but destroy long-term trust. Companies face regulatory action and user backlash.

**Checklist:** [Ethical Design Checklist]
- [ ] Does this design genuinely help users achieve their goals?
- [ ] Would I be comfortable if my family were subjected to this?
- [ ] Is pricing/commitment transparent, or hidden until later?
- [ ] Are we guiding users toward better choices or manipulating them?
- [ ] Do long-term metrics (trust, satisfaction) support this design?
- [ ] Can users easily reverse decisions or opt out?

---

### Domain 4: Clinical Medicine & Healthcare

**Location:** `[[Clinical Medicine 8 - Curated Biases]]`
**Vault Path:** `/Users/tijlkoenderink/Library/Mobile Documents/iCloud~md~obsidian/Documents/Obsidian-Private/01-Private/03-RESOURCES/Cognitive Biases/Curated-Lists/Clinical Medicine 8 - Curated Biases.md`

**High-Risk Biases:**
- **[[Availability Heuristic]]** - Recent case dominates diagnostic thinking; "I just saw this yesterday" overrides base rates
- **[[Premature Closure]]** - Stopping diagnostic search after first plausible explanation; failing to consider alternatives
- **[[Confirmation Bias]]** - Seeking evidence for initial diagnostic impression; dismissing contradictory test results
- **[[Anchoring Bias]]** - Initial symptom or referral diagnosis locks thinking; subsequent information filtered through anchor
- **[[Affective Bias]]** - Emotional patient interactions (likeable, difficult, anxious) distort clinical judgment

**Domain Red Flags:**
- "This is just like the case I saw yesterday"
- Time pressure driving premature diagnostic closure
- Strong emotional reaction to patient (positive or negative)
- Diagnosis made without considering differential
- Dismissing contradictory evidence as "lab error" or "patient misreporting"
- Failure to revisit diagnosis when treatment doesn't work
- "When you hear hoofbeats, think horses not zebras" applied too rigidly

**Mitigation Specific to Domain:**
- **Diagnostic reflection checklist:** Brief pause to consider alternatives; shown to reduce errors by 38%
- **Comprehensive differential:** Require listing 3+ diagnoses before selecting one; prevents premature closure
- **Disconfirming evidence actively sought:** "What would make this diagnosis wrong?" Not just "What confirms it?"
- **Second opinion for complex cases:** Fresh eyes without anchoring to initial impression
- **Documented reasoning before tests:** Write down diagnostic thinking; prevents hindsight bias and forces clarity
- **Revisit when treatment fails:** Non-response is signal to reconsider diagnosis, not increase dose

**Success/Failure Stories:**
- **Success:** Mayo Clinic's systematic differential approach institutionalizes bias mitigation. Complex cases reviewed by teams; explicit consideration of alternatives. Result: diagnostic accuracy industry-leading.
- **Failure:** Common misdiagnoses (heart attack as indigestion, stroke as migraine) often trace to premature closure combined with availability bias. Anchoring on common diagnosis causes rare-but-serious conditions to be missed.

**Checklist:** [From Pre-Decision Checklist - Clinical Section]
- [ ] Have I considered at least 3 possible diagnoses?
- [ ] What evidence would contradict my leading diagnosis?
- [ ] Am I anchored on the referral diagnosis or initial presentation?
- [ ] Is my judgment affected by emotional response to this patient?
- [ ] What's the base rate for this diagnosis in this population?
- [ ] If treatment doesn't work, will I revisit the diagnosis?

---

### Domain 5: Investment & Financial Decisions

**Location:** `[[Munger 25 Tendencies - Curated Biases]]`, `[[Behavioral Economics 12 - Curated Biases]]`
**Vault Paths:**
- `/Users/tijlkoenderink/Library/Mobile Documents/iCloud~md~obsidian/Documents/Obsidian-Private/01-Private/03-RESOURCES/Cognitive Biases/Curated-Lists/Munger 25 Tendencies - Curated Biases.md`
- `/Users/tijlkoenderink/Library/Mobile Documents/iCloud~md~obsidian/Documents/Obsidian-Private/01-Private/03-RESOURCES/Cognitive Biases/Curated-Lists/Behavioral Economics 12 - Curated Biases.md`

**High-Risk Biases:**
- **[[Loss Aversion]]** - Holding losing investments too long (avoiding realization of loss); selling winners too early (securing gain)
- **[[Overconfidence Bias]]** - Believing you can beat the market; underestimating role of luck; excessive trading
- **[[Social Proof]]** - Following the herd into bubbles; "Everyone is buying tech stocks" or "All my friends are in crypto"
- **[[Availability Heuristic]]** - Overweighting recent market moves; recency bias drives allocation decisions
- **[[Sunk Cost Fallacy]]** - Holding investment because "I already put so much in"; averaging down on losers

**Domain Red Flags:**
- "This time is different" (market bubble rationalization)
- FOMO (fear of missing out) driving investment decisions
- Unanimous analyst recommendations (contrarian indicator)
- Ignoring base rates: "What % of similar investments succeeded?"
- Excessive trading (overconfidence in ability to time market)
- Story-driven investing without fundamental analysis
- Emotional attachment to specific holdings

**Mitigation Specific to Domain:**
- **Pre-mortem on investment thesis:** "It's 3 years from now and this investment failed. Why?" Surface risks before committing
- **Base rates first:** What percentage of similar investments (same sector, stage, strategy) succeeded historically?
- **Outside view:** Get opinion from non-invested advisor without emotional attachment
- **Pre-commitment to sell rules:** Define exit criteria before purchase; removes emotion from sell decision
- **Diversification as humility:** Spread risk across assets; admission that you can't predict with certainty
- **Inversion (Munger technique):** "How could I lose money in this?" More powerful than "How will I make money?"

**Success/Failure Stories:**
- **Success:** Charlie Munger's systematic bias awareness and inversion thinking. "Invert, always invert." Explicitly guards against overconfidence, social proof, and availability. Result: Berkshire Hathaway's exceptional long-term returns.
- **Failure:** Dot-com bubble (1999-2000). Social proof ("everyone is getting rich"), overconfidence ("I can spot winners"), availability bias (recent gains extrapolated). Result: $5 trillion in losses when bubble burst.

**Checklist:** [Investment Pre-Decision Checklist]
- [ ] What's the base rate of success for this type of investment?
- [ ] Have I defined specific sell criteria before buying?
- [ ] Am I investing because of FOMO or genuine opportunity?
- [ ] What's the outside view from a non-invested advisor?
- [ ] Have I inverted: "How could this lose money?"
- [ ] Am I holding losers due to sunk cost or genuine potential?

---

### Domain 6: Project Management

**Location:** `[[Project Management 8 - Curated Biases]]`
**Vault Path:** `/Users/tijlkoenderink/Library/Mobile Documents/iCloud~md~obsidian/Documents/Obsidian-Private/01-Private/03-RESOURCES/Cognitive Biases/Curated-Lists/Project Management 8 - Curated Biases.md`

**High-Risk Biases:**
- **[[Planning Fallacy]]** - Systematically underestimating time, cost, and complexity; "It'll only take 2 weeks"
- **[[Optimism Bias]]** - "We've got this" without evidence; underestimating obstacles and overestimating capabilities
- **[[Groupthink]]** - Team consensus without genuine dissent; no one wants to be "negative"
- **[[Sunk Cost Fallacy]]** - Continuing failing projects because of past investment; "We've already spent 6 months"
- **[[Anchoring Bias]]** - Initial estimate dominates planning; subsequent estimates adjust from anchor

**Domain Red Flags:**
- Aggressive timelines with no buffer for unknowns
- No contingency planning: "What could go wrong?"
- Unanimous team confidence without critical examination
- Dismissing risks as "unlikely" without quantification
- Past investment driving continued commitment despite poor progress
- Estimates based on best-case scenarios, not historical data
- "This project is different" (from failed predecessors)

**Mitigation Specific to Domain:**
- **Pre-mortem:** "It's 6 months from now and the project failed catastrophically. Why?" Surfaces 30% more potential problems than standard planning
- **Outside view:** What happened in similar projects? Use historical data, not optimistic imagination
- **Add 50% time buffer:** Research shows projects take 1.5-2x initial estimates; plan accordingly
- **Risk identification before mitigation:** List what could go wrong before discussing solutions; prevents premature dismissal
- **Go/no-go checkpoints:** Define decision points where project can be killed; prevents sunk cost continuation
- **Reference class forecasting:** Find similar past projects; use their actual outcomes for estimation

**Success/Failure Stories:**
- **Success:** Pixar's pre-mortem process ("What could kill this film?") institutionalized before major productions. Catches plot holes, technical limitations, and resource conflicts early when changes are cheap. Result: consistent creative and commercial success.
- **Failure:** Denver International Airport (1995). Planning fallacy led to 16-month delay and $2B cost overrun. Optimism bias dismissed complexity warnings. Sunk cost fallacy prevented cancellation despite mounting problems. Result: became textbook case study in project failure.

**Checklist:** [Project Management Pre-Decision Checklist]
- [ ] Have we conducted a pre-mortem ("Why did this fail?")?
- [ ] What's the outside view? (What happened in similar projects?)
- [ ] Have we added appropriate buffer to estimates (1.5-2x)?
- [ ] What are the specific risks, quantified?
- [ ] Have we defined go/no-go decision points?
- [ ] Are we continuing based on future potential or past investment?

---

### Domain 7: General Decision-Making (Academic Foundation)

**Location:** `[[Kahneman Essential 8 - Curated Biases]]`
**Vault Path:** `/Users/tijlkoenderink/Library/Mobile Documents/iCloud~md~obsidian/Documents/Obsidian-Private/01-Private/03-RESOURCES/Cognitive Biases/Curated-Lists/Kahneman Essential 8 - Curated Biases.md`

**Purpose:** Foundational understanding of cognitive bias science

**High-Risk Biases:** All 8 core Kahneman biases:
- Anchoring Bias
- Availability Heuristic
- Confirmation Bias
- Halo Effect
- Loss Aversion
- Overconfidence Bias
- Planning Fallacy
- Sunk Cost Fallacy

**Use Case:** Understanding System 1 (fast, intuitive, bias-prone) vs System 2 (slow, deliberate, effortful) thinking. This is the theoretical foundation that underlies all domain-specific applications. Start here if you're new to cognitive biases.

**Application:** Not domain-specific, but provides the mental models for understanding *why* biases occur and *how* they operate. Essential for building intuition about when your brain is likely to take shortcuts that lead to errors.

**Key Insight:** Biases aren't character flaws or intelligence deficits—they're features of how human cognition evolved. System 1 thinking is usually correct and always fast, but predictably fails in specific situations. Knowing these situations enables strategic System 2 engagement.

---

### Domain 8: Behavioral Economics & Consumer Behavior

**Location:** `[[Behavioral Economics 12 - Curated Biases]]`
**Vault Path:** `/Users/tijlkoenderink/Library/Mobile Documents/iCloud~md~obsidian/Documents/Obsidian-Private/01-Private/03-RESOURCES/Cognitive Biases/Curated-Lists/Behavioral Economics 12 - Curated Biases.md`

**Purpose:** Understanding and influencing consumer decision-making

**High-Risk Biases:**
- Anchoring (pricing psychology)
- Decoy Effect (choice architecture)
- Default Effect (opt-in vs opt-out)
- Framing Effect (presentation matters)
- Loss Aversion (risk communication)
- Social Proof (consensus influence)

**Use Cases:**
- **Pricing Strategy:** How initial price points anchor perception of value
- **Marketing & Advertising:** Leveraging social proof and framing for persuasion
- **Policy Design:** Using defaults and choice architecture to improve outcomes (pensions, organ donation)
- **Retail & E-commerce:** Product presentation, bundle design, checkout optimization

**Ethical Considerations:**
The power of these biases demands ethical responsibility:
- **Nudge for benefit, not exploitation:** Guide consumers toward choices that serve their interests, not just your profit
- **Transparency:** Make costs, commitments, and alternatives clear
- **Long-term thinking:** Short-term manipulation destroys trust and invites regulation
- **The family test:** Would I want this used on my family members?

**Application:** These biases are tools. A hammer can build or destroy. The same behavioral economics principles that help people save for retirement (default opt-in to 401k) can also trap them in subscriptions they don't want (difficult cancellation). Your choice of application defines whether you're an ethical practitioner or a manipulator.

---

## How to Use This Skill

### Step 1: Identify Your Domain(s)

**Questions to ask:**
- What recurring high-stakes decisions do I make regularly?
- Where do my decisions have the highest impact (hiring, strategy, healthcare, investment, project planning)?
- Which of the 8 curated lists are most relevant to my role and responsibilities?
- Where have I made costly mistakes in the past?

**Action:** Start with 1-2 domains that match your most frequent decision contexts. Don't try to master all 8 at once. Depth in relevant domains beats shallow coverage of everything.

**Example:** A product manager should start with "Product Design & UX" (primary) and "Project Management" (secondary). An executive might choose "Executive/Strategic Decisions" (primary) and "Hiring & Recruitment" (secondary).

---

### Step 2: Read the Curated List

**What to do:**
- Open the curated list in your vault: `Cognitive Biases/Curated-Lists/[Domain Name] - Curated Biases.md`
- Read carefully, focusing on high-risk biases and their consequences in that domain
- Note the domain-specific red flags (warning signs that bias is active)
- Review the domain checklist at the end

**Time investment:** 10-15 minutes of focused reading

**Focus areas:**
1. **High-risk biases:** Which biases cause the most damage in this domain?
2. **Red flags:** What are the warning signs I need to watch for?
3. **Domain checklist:** What questions should I ask before every decision?
4. **Success/failure stories:** What can I learn from others' experiences?

**Goal:** Build mental models of when biases strike in your specific context, not abstract knowledge of biases in general.

---

### Step 3: Deep Dive Top 3 Biases

**Selection criteria:** Choose the 3 biases that:
- Appear most frequently in your domain
- Have caused problems for you in the past
- Have the highest potential cost if unmitigated

**Process:**
1. Use the [[Deep Dive Research]] skill on each of the 3 biases
2. Understand the psychological mechanism (why does this bias occur?)
3. Study domain-specific mitigation strategies in depth
4. Create personal examples from your own experience
5. Develop early-warning system for recognizing the bias in real-time

**Time investment:** 20-30 minutes per bias (1-1.5 hours total)

**Output:** Deep, intuitive understanding of your top 3 threats. You should be able to explain each bias to a colleague and recognize it immediately when it activates.

---

### Step 4: Implement Domain Checklist

**What to do:**
- Extract the domain-specific checklist from your curated list
- Add it to your decision workflow (calendar reminder, project template, pre-meeting checklist)
- Apply the checklist before every significant decision in this domain
- Track results: Did the checklist catch anything? What would have happened without it?

**Integration strategies:**
- **Hiring:** Add checklist to interview scoring template
- **Executive decisions:** Include in pre-meeting agenda for strategic discussions
- **Medical diagnosis:** Build into clinical documentation workflow
- **Project planning:** Include in project kickoff and gate reviews

**Critical rule:** Use checklist *before* the decision, not after. Post-decision review catches nothing; pre-decision review prevents errors.

**Tracking:** Keep log of checklist catches. Examples:
- "Checklist revealed I was anchored on first candidate—reconsidered and hired stronger candidate #3"
- "Pre-mortem surfaced API dependency risk we hadn't considered—added 2 weeks to timeline, project succeeded"
- "Realized I was continuing project due to sunk cost—killed it, saved 3 months"

---

### Step 5: Review Quarterly

**Quarterly review process** (30-45 minutes):

1. **Pattern analysis:** Which biases appeared most frequently in my decisions?
2. **Mitigation effectiveness:** Did my strategies work? What succeeded/failed?
3. **Adjustment:** Based on experience, what changes to my approach?
4. **Expansion:** Ready to add another domain, or deepen existing?

**Questions for reflection:**
- Which biases caught me despite my mitigation efforts?
- What early-warning signs did I miss?
- Which checklist items were most valuable?
- Which items were not useful and can be removed?
- What new red flags have I discovered through experience?

**Output:** Refined, personalized version of domain checklist based on your actual decision patterns. Over time, your checklist becomes increasingly tailored to your specific vulnerabilities.

**Evolution:** Generic → Domain-specific → Role-specific → Personal. The ultimate goal is a personal bias mitigation system tuned to your individual blind spots.

---

## Cross-Domain Patterns

Certain bias triggers appear across all domains:

### 1. Time Pressure
- **Effect:** Activates System 1 thinking; disables deliberate System 2 analysis
- **Biases amplified:** All of them, but especially premature closure, availability heuristic, and confirmation bias
- **Mitigation:** Build decision time into schedule; avoid "urgent" decisions when possible; have pre-prepared frameworks for time-critical situations

### 2. Emotional Activation
- **Effect:** Emotion hijacks analytical thinking; gut feeling overrides evidence
- **Biases amplified:** Affective bias, confirmation bias (seeking evidence for emotional conclusion), loss aversion
- **Mitigation:** Notice emotional activation ("I'm angry/excited/anxious"); delay decision if possible; consult framework/checklist

### 3. Social Pressure
- **Effect:** Conformity drives out independent analysis; fear of dissent silences concerns
- **Biases amplified:** Groupthink, social proof, authority bias
- **Mitigation:** Anonymous input before group discussion; designated devil's advocate; leader speaks last

### 4. High Stakes
- **Effect:** Paradoxically, highest-impact decisions often receive least rigorous analysis due to pressure
- **Biases amplified:** Overconfidence (pressure to appear decisive), confirmation bias (need to justify decision), groupthink (need for consensus)
- **Mitigation:** Highest-stakes decisions demand most rigorous process; use checklist without exception

### 5. Success Streak
- **Effect:** Recent wins breed overconfidence; "we can't lose" mentality emerges
- **Biases amplified:** Overconfidence bias, optimism bias, dismissal of risks
- **Mitigation:** Track wins and losses; remember that regression to mean is inevitable; success is often luck disguised as skill

### Universal Principles:
- **Structured process helps everywhere:** Checklists, frameworks, and documentation mitigate biases across domains
- **Documentation prevents hindsight bias:** Write down reasoning before outcome is known; prevents "I knew it all along"
- **Outside view is universally valuable:** "What happened to others?" grounds optimism in reality
- **Dissent is precious:** The person who disagrees might be wrong, but they prevent groupthink

---

## Building Domain Expertise

### Month 1: Foundation
- **Week 1-2:** Read curated list thoroughly; identify high-risk biases and red flags
- **Week 3-4:** Apply domain checklist to every decision; notice when biases activate
- **Goal:** Recognition—can you spot the biases in real-time?

### Month 2: Deep Understanding
- **Week 1:** Deep dive on bias #1 (highest risk)
- **Week 2:** Deep dive on bias #2
- **Week 3:** Deep dive on bias #3
- **Week 4:** Practice explaining biases to others; teaching deepens understanding
- **Goal:** Mechanistic understanding—why do these biases occur?

### Month 3: Integration
- **Daily:** Apply checklist consistently before decisions
- **Weekly:** Review decisions made; identify bias patterns
- **Goal:** Habit formation—bias check becomes automatic

### Month 4+: Refinement
- **Ongoing:** Track checklist effectiveness; remove low-value items, add new discoveries
- **Quarterly:** Review patterns; adjust mitigation strategies based on experience
- **Yearly:** Consider expanding to additional domain
- **Goal:** Personalization—system tailored to your specific vulnerabilities

### Teaching Others
- Teaching is the ultimate test of understanding
- Explain your domain's high-risk biases to a colleague
- Share your checklist and success stories
- Build organizational culture of bias awareness

**Timeline note:** This is a marathon, not a sprint. Genuine expertise takes months of consistent application. But improvements appear within weeks—even partial bias mitigation creates measurable decision quality gains.

---

## Related Skills

This skill works synergistically with other cognitive bias skills in your system:

- **[[Quick Recognition]]** - Real-time identification of active biases during decisions; complements this skill's domain-specific preparation
- **[[Pre-Decision Checklist]]** - Systematic application of bias mitigation; provides the operational framework for executing domain-specific strategies
- **[[Deep Dive Research]]** - Understanding specific biases deeply; use for the top 3 biases in your domain
- **[[Mitigation Strategies]]** - Practical techniques for counteracting biases once identified; domain-specific versions integrated into curated lists

**Skill sequence for maximum impact:**
1. Start here (Domain-Specific Application) to identify relevant biases for your context
2. Use Deep Dive Research on top 3 biases to build deep understanding
3. Implement Pre-Decision Checklist with domain-specific items
4. Practice Quick Recognition during actual decisions
5. Apply Mitigation Strategies when biases are caught

**Integration:** These skills aren't separate tools—they're phases of a unified bias mitigation system. Domain-Specific Application is the foundation that makes the other skills actionable in your actual work context.

---

## Summary

Domain-specific bias awareness transforms abstract knowledge into concrete decision improvements. By focusing on the biases that matter most in your specific context, you build targeted vigilance where it counts. The curated lists provide battle-tested guidance; your job is to internalize them through consistent application.

Start with one domain. Master its high-risk biases, red flags, and checklist. Build the habit of bias-checking before decisions. Track your wins. Refine your approach quarterly. Over time, bias mitigation becomes intuitive—not a burdensome process, but a natural part of quality decision-making.

The goal isn't perfection. Biases will still catch you sometimes—they're hardwired into human cognition. The goal is improvement: fewer costly mistakes, earlier catches, faster recovery. A 20% reduction in bias-driven errors compounds dramatically over years of decisions.

Your domain is your laboratory. The curated lists are your map. Your decisions are your practice. Begin today.
